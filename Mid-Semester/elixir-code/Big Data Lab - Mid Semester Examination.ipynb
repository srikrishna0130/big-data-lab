{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: R Mukesh\n",
    "### Roll No. CED15I002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from craved import eda\n",
    "dataset = eda.eda()\n",
    "\n",
    "# Attributes to read dataset function\n",
    "filename = 'spambase.data'\n",
    "usecolumns = None # Use all the columns in the dataset\n",
    "targetcol = -1 # use the last column as target\n",
    "encode_target = False # Don't encode the target values\n",
    "\n",
    "dataset.read_data_csv(filename, usecols=usecolumns, target_col=targetcol, encode_target=encode_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardardize the features\n",
    "dataset.standardize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.3 # Portion of data samples used for testing\n",
    "data_train, data_test, target_train, target_test = train_test_split(dataset.data, dataset.target, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Decision Tree Model on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 99.90683229813665 %\n",
      "Testing Accuracy = 90.65894279507603 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Parameters for the decision tree\n",
    "criterion = 'gini' # Options = ['gini', 'entropy']\n",
    "max_depth = None # Max depth of tree (None: until all leaves are pure)\n",
    "\n",
    "# Train the decision tree model with the training data\n",
    "decison_tree_classifier = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth)\n",
    "decison_tree_classifier.fit(data_train, target_train)\n",
    "\n",
    "# Compute the training and testing accuracy of the classifier\n",
    "training_accuracy = decison_tree_classifier.score(data_train, target_train)\n",
    "testing_accuracy = decison_tree_classifier.score(data_test, target_test)\n",
    "\n",
    "print(\"Training Accuracy = {} %\".format(training_accuracy*100))\n",
    "print(\"Testing Accuracy = {} %\".format(testing_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Naive Bayes Classifier Model on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 81.42857142857143%\n",
      "Testing Accuracy = 80.95582910934105 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussian_nb_classifier = GaussianNB()\n",
    "gaussian_nb_classifier.fit(data_train, target_train)\n",
    "\n",
    "# Compute the training and testing accuracy of the classifier\n",
    "training_accuracy = gaussian_nb_classifier.score(data_train, target_train)\n",
    "testing_accuracy = gaussian_nb_classifier.score(data_test, target_test)\n",
    "\n",
    "print(\"Training Accuracy = {}%\".format(training_accuracy*100))\n",
    "print(\"Testing Accuracy = {} %\".format(testing_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute performance measures for Decision Tree Classifier on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Performance Metrics\n",
      "Precision = 0.875\n",
      "Recall = 0.8938848920863309\n",
      "F1-Score = 0.8843416370106761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Compute the performance metrics for the Decision Tree Classifier\n",
    "dt_pred_labels = decison_tree_classifier.predict(data_test)\n",
    "\n",
    "dt_precision = precision_score(target_test, dt_pred_labels)\n",
    "dt_recall = recall_score(target_test, dt_pred_labels)\n",
    "dt_f1_score = f1_score(target_test, dt_pred_labels)\n",
    "\n",
    "print(\"Decision Tree Classifier Performance Metrics\")\n",
    "print(\"Precision = {}\".format(dt_precision))\n",
    "print(\"Recall = {}\".format(dt_recall))\n",
    "print(\"F1-Score = {}\".format(dt_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Classification Performance Measures (Decision Tree)\n",
    "\n",
    "Precision = 0.866\n",
    "\n",
    "Out of all mails classified by classifier as spam, 86.63 % of is actually spam, the rest are not spam. It implies about 13.37% of mail are not spam, which is not acceptable.\n",
    "\n",
    "SPAM DETECTORS must ideally have precision = 1.0\n",
    "\n",
    "Recall = 0.8974\n",
    "\n",
    "Out of all spam mails, the system detects 89.74 % as spam, which is good.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute performance measures for Gaussian Naive Bayes Classifier on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Classifier Performance Metrics\n",
      "Precision = 0.6945551128818062\n",
      "Recall = 0.9406474820143885\n",
      "F1-Score = 0.7990832696715051\n"
     ]
    }
   ],
   "source": [
    "# Compute the performance metrics for the Decision Tree Classifier\n",
    "gnb_pred_labels = gaussian_nb_classifier.predict(data_test)\n",
    "\n",
    "gnb_precision = precision_score(target_test, gnb_pred_labels)\n",
    "gnb_recall = recall_score(target_test, gnb_pred_labels)\n",
    "gnb_f1_score = f1_score(target_test, gnb_pred_labels)\n",
    "\n",
    "print(\"Gaussian Naive Bayes Classifier Performance Metrics\")\n",
    "print(\"Precision = {}\".format(gnb_precision))\n",
    "print(\"Recall = {}\".format(gnb_recall))\n",
    "print(\"F1-Score = {}\".format(gnb_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Classification Performance Measures (Naive Bayes)\n",
    "\n",
    "Precision = 0.69455 (Naive Bayes)\n",
    "\n",
    "Out of all mails classified by classifier as spam, 69.45 % of is actually spam, the rest are not spam. It implies about 30.1% of mail are not spam, which is not worst as it can get.\n",
    "\n",
    "SPAM DETECTORS must ideally have precision = 1.0\n",
    "\n",
    "Recall = 0.94064\n",
    "\n",
    "Out of all spam mails, the system detects 89.74 % as spam, which is good, but this comes at cost of precision which is not dedsirable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the datasaet Introduce Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import nan\n",
    "\n",
    "filename = 'spambase.data'\n",
    "data_with_missing_values = read_csv(filename, index_col=-1, dtype=float)\n",
    "\n",
    "from numpy.random import randint\n",
    "\n",
    "n_samples, n_featues = data_with_missing_values.shape\n",
    "n_missing_values = 20\n",
    "\n",
    "# Introduce 'n_missing_values' missing values indicated by np.nan\n",
    "for i in range(n_missing_values):\n",
    "    i_data = randint(0, n_samples)\n",
    "    j_data = randint(0, n_featues)\n",
    "    data_with_missing_values.iat[i_data, j_data] = nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Drop all data points with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in Dataset:\n",
      "Before dropping NA rows = 4600\n",
      "After dropping NA rows = 4580\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with any missing values\n",
    "data_without_missing_values_method1 = data_with_missing_values.dropna()\n",
    "\n",
    "print(\"Number of Samples in Dataset:\")\n",
    "print(\"Before dropping NA rows = {}\".format(data_with_missing_values.shape[0]))\n",
    "print(\"After dropping NA rows = {}\".format(data_without_missing_values_method1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Imputing missing values (Replace with column statistics: Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Fill value for Imputation\n",
      "[1.04576087e-01 2.12921739e-01 2.80578261e-01 6.54391304e-02\n",
      " 3.12221739e-01 9.59425962e-02 1.14232609e-01 1.05317391e-01\n",
      " 9.01065449e-02 2.39506414e-01 5.98369565e-02 5.41680435e-01\n",
      " 9.39500000e-02 5.86518808e-02 4.92152174e-02 2.48832609e-01\n",
      " 1.42554903e-01 1.84544466e-01 1.66217004e+00 8.55956522e-02\n",
      " 8.09728261e-01 1.21228261e-01 1.01667391e-01 9.42891304e-02\n",
      " 5.49623913e-01 2.65441304e-01 7.67471739e-01 1.24871739e-01\n",
      " 9.89369565e-02 1.02873913e-01 6.47814742e-02 4.70586957e-02\n",
      " 9.72500000e-02 4.78560557e-02 1.05457708e-01 9.75402349e-02\n",
      " 1.36982609e-01 1.32072190e-02 7.86456522e-02 6.48478261e-02\n",
      " 4.36760870e-02 1.32396173e-01 4.61086957e-02 7.92130435e-02\n",
      " 3.01354642e-01 1.79799957e-01 5.44565217e-03 3.18760870e-02\n",
      " 3.85914329e-02 1.39060652e-01 1.69795652e-02 2.69018700e-01\n",
      " 7.58271739e-02 4.42392344e-02 5.19182717e+00 5.21708696e+01\n",
      " 2.83290435e+02]\n",
      "Number of Features = 57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Replace the missing value with column mean\n",
    "imputer_method2 = Imputer(missing_values=nan, strategy='mean')\n",
    "data_without_missing_values_method2 = imputer_method2.fit_transform(data_with_missing_values)\n",
    "\n",
    "# Print the imputation fill value for each feature\n",
    "print(\"Columns Fill value for Imputation\")\n",
    "print(imputer_method2.statistics_)\n",
    "print(\"Number of Features = {}\".format(data_without_missing_values_method2.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Imputing missing values (Replace with column statistics: Median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Fill value for Imputation\n",
      "[0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e-01\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 1.3100e+00 0.0000e+00 2.2000e-01 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 6.5000e-02 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 2.2755e+00 1.5000e+01 9.5000e+01]\n",
      "Number of Features = 57\n"
     ]
    }
   ],
   "source": [
    "# Replace the missing value with column mean\n",
    "imputer_method3 = Imputer(missing_values=nan, strategy='median')\n",
    "data_without_missing_values_method3 = imputer_method3.fit_transform(data_with_missing_values)\n",
    "\n",
    "# Print the imputation fill value for each feature\n",
    "print(\"Columns Fill value for Imputation\")\n",
    "print(imputer_method3.statistics_)\n",
    "print(\"Number of Features = {}\".format(data_without_missing_values_method3.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform K-Means Clustering on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform K-Means on data\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 2 # Number of clusters\n",
    "n_init = 10 # Number of times KMeans will be run with different centroid measures\n",
    "\n",
    "kmeans_clusterer = KMeans(n_clusters=n_clusters, n_init=n_init)\n",
    "kmeans_clusterer.fit(dataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the quality of the clusters (Internal Indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Cluster Indices\n",
      "Sillhouette Score = 0.659630943933575\n",
      "Ball Hall Index = 72.9263569728552\n",
      "Davies-Bouldin Index = 0.612659465627403\n",
      "Hartigan Index = -270.6757054681185\n",
      "Ray-Turi Index = 0.09017531095646855\n"
     ]
    }
   ],
   "source": [
    "from craved import internal_indices\n",
    "\n",
    "# Compute some important internal quality indices for cluster\n",
    "internal_validation = internal_indices.internal_indices(dataset.data, kmeans_clusterer.labels_)\n",
    "silhouette_score = internal_validation.silhouette_score()\n",
    "ball_hall_index = internal_validation.ball_hall_index()\n",
    "davies_bouldin_index = internal_validation.davies_bouldin_index()\n",
    "hartigan_index = internal_validation.hartigan_index()\n",
    "ray_turi_index = internal_validation.ray_turi_index()\n",
    "\n",
    "print(\"Internal Cluster Indices\")\n",
    "print(\"Sillhouette Score = {}\".format(silhouette_score))\n",
    "print(\"Ball Hall Index = {}\".format(ball_hall_index))\n",
    "print(\"Davies-Bouldin Index = {}\".format(davies_bouldin_index))\n",
    "print(\"Hartigan Index = {}\".format(hartigan_index))\n",
    "print(\"Ray-Turi Index = {}\".format(ray_turi_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the quality of the clusters (External Indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External Cluster Indices\n",
      "Purity = 0.6059552271245382\n",
      "Folkes-Mallow Index = 0.7157652067983051\n",
      "Adjusted Rand Index = -0.00494969888751084\n",
      "Jaccard Coefficient = 0.5165095187012068\n",
      "Homogenity Score = 0.005547513020778736\n"
     ]
    }
   ],
   "source": [
    "from craved import external_indices\n",
    "\n",
    "# Compute some important external quality indices for cluster\n",
    "external_validation = external_indices.external_indices(dataset.target, kmeans_clusterer.labels_)\n",
    "purity = external_validation.purity()\n",
    "folkes_mallows_index = external_validation.folkes_mallows_index()\n",
    "adjusted_rand_index = external_validation.adjusted_rand_index()\n",
    "jaccard_coeff = external_validation.jaccard_coeff()\n",
    "homogeneity_score = external_validation.homogeneity_score()\n",
    "\n",
    "print(\"External Cluster Indices\")\n",
    "print(\"Purity = {}\".format(purity))\n",
    "print(\"Folkes-Mallow Index = {}\".format(folkes_mallows_index))\n",
    "print(\"Adjusted Rand Index = {}\".format(adjusted_rand_index))\n",
    "print(\"Jaccard Coefficient = {}\".format(jaccard_coeff))\n",
    "print(\"Homogenity Score = {}\".format(homogeneity_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
